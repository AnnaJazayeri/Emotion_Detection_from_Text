{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba80f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, itertools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import preprocessor as p\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import little_mallet_wrapper\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.classify import SklearnClassifier\n",
    "# pip install -U imbalanced-learn scikit-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3c80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed1b6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Emotion    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with column names\n",
    "column_names = ['Text', 'Emotion']\n",
    "train_data = pd.read_excel(\"Tweet Emotion Dataset.xlsx\", names=column_names)\n",
    "\n",
    "# Check for missing values\n",
    "print(train_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e84274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Emotion\n",
       "0  @ArcticFantasy I would have almost took offens...   anger\n",
       "1  @IllinoisLoyalty that Rutgers game was an abom...   anger\n",
       "2  @CozanGaming that's what lisa asked before she...   anger\n",
       "3  Sometimes I get mad over something so minuscul...   anger\n",
       "4  Sometimes I get mad over something so minuscul...   anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38fc73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           would almost took offense actually snapped\n",
      "1    rutgers game abomination affront must never speak\n",
      "2                 thats lisa asked started raging call\n",
      "3    sometimes something minuscule ruin somebody li...\n",
      "4    sometimes something minuscule ruin somebody li...\n",
      "5    think must actually working like havent snap c...\n",
      "6    eye dilated hate world right rage thousand fie...\n",
      "7    chosen member seat people dole mate elect cand...\n",
      "8    chosen member seat people dole mate elect cand...\n",
      "9         please canadian player play player atrocious\n",
      "Name: CleanedText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_text_data(text):\n",
    "    # Apply preprocessor\n",
    "    text = p.clean(text)\n",
    "\n",
    "    # Remove HTML tags and URLs\n",
    "    text = re.sub(r'<[^>]+>|http[s]?://\\S+|http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation and replace words with multiple consecutive letters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1', text)\n",
    "    \n",
    "    # Insert a space before all capital letters in the middle of a sentence\n",
    "    text = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    # Tokenize the tweet using TweetTokenizer\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    word_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Stop word removal and length filtering\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.remove('not')\n",
    "    filtered_text = [word for word in word_tokens if word.isalnum() and len(word) > 3 and word.lower() not in stop_words]\n",
    "\n",
    "    # Lowercase change\n",
    "    text = ' '.join(filtered_text).lower()\n",
    "\n",
    "    # Lemmatization using WordNet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'TweetText' is the column to be cleaned\n",
    "train_data['CleanedText'] = train_data['Text'].apply(clean_text_data)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(train_data['CleanedText'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaf147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56fc98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont      5.985417\n",
      "would     5.730211\n",
      "like      5.628274\n",
      "make      5.558357\n",
      "thats     4.406965\n",
      "love      4.227535\n",
      "people    4.086973\n",
      "want      3.574861\n",
      "think     3.368157\n",
      "thing     3.224520\n",
      "cant      3.047184\n",
      "really    3.029157\n",
      "much      2.902642\n",
      "even      2.844056\n",
      "week      2.798210\n",
      "little    2.767322\n",
      "feel      2.727057\n",
      "give      2.651678\n",
      "look      2.571878\n",
      "didnt     2.561387\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# TF IDF vectorizer with adjusted parameters\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform\n",
    "matrix_tfidf = tfidf_vect.fit_transform(train_data['CleanedText'])\n",
    "\n",
    "# Using get_feature_names_out\n",
    "featureNames = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "# Data frame for our matrix_tfidf and featureNames\n",
    "df_tfidf = pd.DataFrame(data=matrix_tfidf.toarray(), columns=featureNames)\n",
    "\n",
    "# Adding up the importance scores (= TF-IDF scores) for every word.\n",
    "wordScores = df_tfidf.sum(axis=0)\n",
    "\n",
    "# Sorting words according to how much they matter in all the tweets\n",
    "# Sorting them with their overall TF-IDF scores.\n",
    "top20words = wordScores.sort_values(ascending=False).head(20)\n",
    "\n",
    "# Print top20words\n",
    "print(top20words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293e7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c582b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the training data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X = train_data['CleanedText'].values.reshape(-1, 1)\n",
    "y = train_data['Emotion'].values\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# convert text (object) data to string for w2v\n",
    "X_resampled= [str(obj) for obj in X_resampled]\n",
    "X_resampled = np.array(X_resampled)\n",
    "\n",
    "# resource : https://www.kaggle.com/code/titanpointe/cyberbullying-tweets-eda-automl-dl-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1dfa83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411c587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec Model\n",
    "sentences = [word_tokenize(text) for text in X_resampled]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)  # Adjust parameters as needed\n",
    "\n",
    "# Convert Text to Embeddings\n",
    "def get_embedding(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # Filter out tokens that are not in the vocabulary\n",
    "    tokens = [token for token in tokens if token in word2vec_model.wv.key_to_index]\n",
    "    if len(tokens) > 0:\n",
    "        # Return the average of word embeddings for the tokens\n",
    "        return np.mean([word2vec_model.wv[t] for t in tokens], axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create an array of embeddings for each text\n",
    "X_resampled = [get_embedding(text) for text in X_resampled]\n",
    "\n",
    "# resource: https://www.kaggle.com/code/titanpointe/cyberbullying-tweets-eda-automl-dl-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16eaf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e73cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324f0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       1.00      0.00      0.00        28\n",
      "        fear       1.00      0.00      0.00        22\n",
      "         joy       0.20      1.00      0.34        18\n",
      "     sadness       1.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.20        88\n",
      "   macro avg       0.80      0.25      0.08        88\n",
      "weighted avg       0.84      0.20      0.07        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Logistic Regression model\n",
    "logistic_regression_classifier = LogisticRegression(max_iter=1000)\n",
    "logistic_regression_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logistic = logistic_regression_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logistic, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47eb0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.43      0.53        28\n",
      "        fear       0.63      0.77      0.69        22\n",
      "         joy       0.69      0.61      0.65        18\n",
      "     sadness       0.50      0.70      0.58        20\n",
      "\n",
      "    accuracy                           0.61        88\n",
      "   macro avg       0.63      0.63      0.61        88\n",
      "weighted avg       0.64      0.61      0.61        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Random Forest model\n",
    "random_forest_classifier = RandomForestClassifier(random_state=42)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = random_forest_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4cdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c098ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.43      0.53        28\n",
      "        fear       0.65      0.68      0.67        22\n",
      "         joy       0.43      0.67      0.52        18\n",
      "     sadness       0.65      0.65      0.65        20\n",
      "\n",
      "    accuracy                           0.59        88\n",
      "   macro avg       0.61      0.61      0.59        88\n",
      "weighted avg       0.62      0.59      0.59        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Decision Tree model\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dt = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77174c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe3d1f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        28\n",
      "        fear       1.00      0.00      0.00        22\n",
      "         joy       0.24      0.33      0.28        18\n",
      "     sadness       0.27      0.85      0.41        20\n",
      "\n",
      "    accuracy                           0.26        88\n",
      "   macro avg       0.38      0.30      0.17        88\n",
      "weighted avg       0.36      0.26      0.15        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Support Vector Machines model\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machines Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b3353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f854ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d705a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
